{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44346143",
   "metadata": {},
   "source": [
    "# 03 Transformer Models (Planned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576c6d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aafe11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/train.tsv exists: True\n",
      "../data/raw/valid.tsv exists: True\n",
      "../data/raw/test.tsv exists: True\n",
      "\n",
      "--- train raw head ---\n",
      "2635.json\tfalse\tSays the Annies List political group supports third-trimester abortions on demand.\tabortion\tdwayne-bohac\tState representative\tTexas\trepublican\t0\t1\t0\t0\t0\ta mailer\n",
      "10540.json\thalf-true\tWhen did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.\tenergy,history,job-accomplishments\tscott-surovell\tState delegate\tVirginia\tdemocrat\t0\t0\t1\t1\t0\ta floor speech.\n",
      "\n",
      "--- valid raw head ---\n",
      "12134.json\tbarely-true\tWe have less Americans working now than in the 70s.\teconomy,jobs\tvicky-hartzler\tU.S. Representative\tMissouri\trepublican\t1\t0\t1\t0\t0\tan interview with ABC17 News\n",
      "238.json\tpants-fire\tWhen Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\tobama-birth-certificate,religion\tchain-email\t\t\tnone\t11\t43\t8\t5\t105\t\n",
      "\n",
      "--- test raw head ---\n",
      "11972.json\ttrue\tBuilding a wall on the U.S.-Mexico border will take literally years.\timmigration\trick-perry\tGovernor\tTexas\trepublican\t30\t30\t42\t23\t18\tRadio interview\n",
      "11685.json\tfalse\tWisconsin is on pace to double the number of layoffs this year.\tjobs\tkatrina-shankland\tState representative\tWisconsin\tdemocrat\t2\t1\t0\t0\t0\ta news conference\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"../data/raw/train.tsv\"\n",
    "VALID_PATH = \"../data/raw/valid.tsv\"\n",
    "TEST_PATH  = \"../data/raw/test.tsv\"\n",
    "\n",
    "for p in [TRAIN_PATH, VALID_PATH, TEST_PATH]:\n",
    "    print(p, \"exists:\", os.path.exists(p))\n",
    "\n",
    "# Raw peek (first 2 lines)\n",
    "for name, p in [(\"train\", TRAIN_PATH), (\"valid\", VALID_PATH), (\"test\", TEST_PATH)]:\n",
    "    print(\"\\n---\", name, \"raw head ---\")\n",
    "    with open(p, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for _ in range(2):\n",
    "            print(f.readline().rstrip(\"\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349d9420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes: (10240, 2) (1284, 2) (1267, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                          statement\n",
       "0        false  Says the Annies List political group supports ...\n",
       "1    half-true  When did the decline of coal start? It started...\n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3        false  Health care reform legislation is likely to ma...\n",
       "4    half-true  The economic turnaround started at the end of ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_liar_basic(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=\"\\t\",\n",
    "        header=None,          # LIAR has no header\n",
    "        dtype=str,\n",
    "        keep_default_na=False # keep empty strings as empty strings\n",
    "    )\n",
    "\n",
    "    # LIAR: col 1 = label, col 2 = statement\n",
    "    df = df[[1, 2]].rename(columns={1: \"label\", 2: \"statement\"})\n",
    "    return df\n",
    "\n",
    "train_df = load_liar_basic(TRAIN_PATH)\n",
    "valid_df = load_liar_basic(VALID_PATH)\n",
    "test_df  = load_liar_basic(TEST_PATH)\n",
    "\n",
    "print(\"Loaded shapes:\", train_df.shape, valid_df.shape, test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaffcb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts (before filter): {'half-true': 2114, 'false': 1995, 'mostly-true': 1962, 'true': 1676, 'barely-true': 1654, 'pants-fire': 839}\n",
      "Label counts (before filter): {'false': 263, 'mostly-true': 251, 'half-true': 248, 'barely-true': 237, 'true': 169, 'pants-fire': 116}\n",
      "Label counts (before filter): {'half-true': 265, 'false': 249, 'mostly-true': 241, 'barely-true': 212, 'true': 208, 'pants-fire': 92}\n",
      "Final shapes: (10240, 2) (1284, 2) (1267, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  labels\n",
       "0  Says the Annies List political group supports ...       1\n",
       "1  When did the decline of coal start? It started...       3\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...       4\n",
       "3  Health care reform legislation is likely to ma...       1\n",
       "4  The economic turnaround started at the end of ...       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = [\"pants-fire\", \"false\", \"barely-true\", \"half-true\", \"mostly-true\", \"true\"]\n",
    "LABEL2ID = {l: i for i, l in enumerate(LABELS)}\n",
    "ID2LABEL = {i: l for l, i in LABEL2ID.items()}\n",
    "\n",
    "def normalize_label(x: str) -> str:\n",
    "    x = (x or \"\").strip().lower()\n",
    "    x = x.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "    x = re.sub(r\"-+\", \"-\", x)\n",
    "    return x\n",
    "\n",
    "def prepare_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"statement\"] = df[\"statement\"].astype(str).fillna(\"\").str.strip()\n",
    "    df[\"label\"] = df[\"label\"].astype(str).map(normalize_label)\n",
    "\n",
    "    print(\"Label counts (before filter):\", df[\"label\"].value_counts().head(10).to_dict())\n",
    "\n",
    "    df = df[df[\"label\"].isin(LABEL2ID)].copy()\n",
    "    df[\"labels\"] = df[\"label\"].map(LABEL2ID).astype(int)\n",
    "\n",
    "    # Keep only what the model needs\n",
    "    df = df[[\"statement\", \"labels\"]].reset_index(drop=True)\n",
    "\n",
    "    # Safety check\n",
    "    assert len(df) > 0, \"DataFrame became empty after filtering. Check label mapping / TSV parsing.\"\n",
    "    return df\n",
    "\n",
    "train_df = prepare_df(train_df)\n",
    "valid_df = prepare_df(valid_df)\n",
    "test_df  = prepare_df(test_df)\n",
    "\n",
    "print(\"Final shapes:\", train_df.shape, valid_df.shape, test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb0759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lengths: 10240 1284 1267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'statement': 'Says the Annies List political group supports third-trimester abortions on demand.',\n",
       " 'labels': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "valid_ds = Dataset.from_pandas(valid_df, preserve_index=False)\n",
    "test_ds  = Dataset.from_pandas(test_df,  preserve_index=False)\n",
    "\n",
    "print(\"Dataset lengths:\", len(train_ds), len(valid_ds), len(test_ds))\n",
    "train_ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730d609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 100/100 [00:00<00:00, 263.09it/s, Materializing param=distilbert.transformer.layer.5.sa_layer_norm.weight]   \n",
      "\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "classifier.weight       | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"  # fast baseline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(LABEL2ID),\n",
    "    id2label=ID2LABEL,\n",
    "    label2id=LABEL2ID,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5f659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10240/10240 [00:00<00:00, 11514.19 examples/s]\n",
      "Map: 100%|██████████| 1284/1284 [00:00<00:00, 13171.63 examples/s]\n",
      "Map: 100%|██████████| 1267/1267 [00:00<00:00, 11416.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized columns: ['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Example: {'labels': tensor(1), 'input_ids': tensor([  101,  2758,  1996,  8194,  2015,  2862,  2576,  2177,  6753,  2353,\n",
      "         1011, 12241, 20367, 11324,  2015,  2006,  5157,  1012,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 64\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"statement\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "train_tok = train_ds.map(tokenize_batch, batched=True, remove_columns=[\"statement\"])\n",
    "valid_tok = valid_ds.map(tokenize_batch, batched=True, remove_columns=[\"statement\"])\n",
    "test_tok  = test_ds.map(tokenize_batch,  batched=True, remove_columns=[\"statement\"])\n",
    "\n",
    "# Make sure Trainer sees torch tensors for the numeric fields only\n",
    "train_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "valid_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_tok.set_format(type=\"torch\",  columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Tokenized columns:\", train_tok.column_names)\n",
    "print(\"Example:\", train_tok[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1d7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_macro\": pr,\n",
    "        \"recall_macro\": rc,\n",
    "        \"f1_macro\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5fb0c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=True,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=False,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "enable_jit_checkpoint=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "fp16=False,\n",
       "fp16_full_eval=False,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=True,\n",
       "group_by_length=False,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_revision=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_num_input_tokens_seen=no,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "liger_kernel_config=None,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=-1,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=None,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=50,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs=None,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=300,\n",
       "metric_for_best_model=f1_macro,\n",
       "neftune_noise_alpha=None,\n",
       "num_train_epochs=1,\n",
       "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=../results/transformer_runs,\n",
       "parallelism_config=None,\n",
       "per_device_eval_batch_size=16,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "project=huggingface,\n",
       "push_to_hub=False,\n",
       "remove_unused_columns=False,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=None,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.EPOCH,\n",
       "save_total_limit=1,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "trackio_space_id=trackio,\n",
       "use_cache=False,\n",
       "use_cpu=False,\n",
       "use_liger_kernel=False,\n",
       "warmup_ratio=None,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "RUN_DIR = \"../results/transformer_runs\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "common_args = dict(\n",
    "    output_dir=RUN_DIR,\n",
    "\n",
    "    # ↓ safer memory settings (avoid kernel crash)\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    num_train_epochs=1,\n",
    "    max_steps=300,  # ✅ Option A: stop early (quick run)\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    "\n",
    "    # ✅ stability in notebooks / prevents dataloader worker crashes\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "\n",
    "    # ✅ avoids some Trainer/dataset column issues\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "try:\n",
    "    training_args = TrainingArguments(\n",
    "        **common_args,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "    )\n",
    "except TypeError:\n",
    "    training_args = TrainingArguments(\n",
    "        **common_args,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "    )\n",
    "\n",
    "training_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7838be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x799d3ba16d80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer_kwargs = dict(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=valid_tok,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "try:\n",
    "    trainer = Trainer(**trainer_kwargs, tokenizer=tokenizer)\n",
    "except TypeError:\n",
    "    trainer = Trainer(**trainer_kwargs)\n",
    "\n",
    "trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41a8d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 04:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.730175</td>\n",
       "      <td>1.736202</td>\n",
       "      <td>0.235202</td>\n",
       "      <td>0.141734</td>\n",
       "      <td>0.195922</td>\n",
       "      <td>0.136485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=1.7452124786376952, metrics={'train_runtime': 298.5285, 'train_samples_per_second': 8.039, 'train_steps_per_second': 1.005, 'total_flos': 24566175524736.0, 'train_loss': 1.7452124786376952, 'epoch': 0.234375})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "train_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc921024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: {'eval_loss': 1.7362022399902344, 'eval_accuracy': 0.235202492211838, 'eval_precision_macro': 0.14173356543079718, 'eval_recall_macro': 0.19592159743145446, 'eval_f1_macro': 0.13648470159419065, 'eval_runtime': 37.5168, 'eval_samples_per_second': 34.225, 'eval_steps_per_second': 2.159, 'epoch': 0.234375}\n",
      "TEST : {'eval_loss': 1.716438889503479, 'eval_accuracy': 0.23283346487766376, 'eval_precision_macro': 0.11467515772245412, 'eval_recall_macro': 0.1983185017006359, 'eval_f1_macro': 0.13390705378410298, 'eval_runtime': 36.6039, 'eval_samples_per_second': 34.614, 'eval_steps_per_second': 2.186, 'epoch': 0.234375}\n"
     ]
    }
   ],
   "source": [
    "valid_metrics = trainer.evaluate(eval_dataset=valid_tok)\n",
    "test_metrics  = trainer.evaluate(eval_dataset=test_tok)\n",
    "\n",
    "print(\"VALID:\", valid_metrics)\n",
    "print(\"TEST :\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9688db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- ../results/transformer_valid_metrics.json\n",
      "- ../results/transformer_test_metrics.json\n",
      "- ../results/transformer_test_predictions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>labels</th>\n",
       "      <th>pred_id</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>mostly-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  labels  pred_id  \\\n",
       "0  Building a wall on the U.S.-Mexico border will...       5        1   \n",
       "1  Wisconsin is on pace to double the number of l...       1        4   \n",
       "2  Says John McCain has done nothing to help the ...       1        1   \n",
       "3  Suzanne Bonamici supports a plan that will cut...       3        1   \n",
       "4  When asked by a reporter whether hes at the ce...       0        1   \n",
       "\n",
       "    pred_label  \n",
       "0        false  \n",
       "1  mostly-true  \n",
       "2        false  \n",
       "3        false  \n",
       "4        false  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save metrics\n",
    "with open(os.path.join(RESULTS_DIR, \"transformer_valid_metrics.json\"), \"w\") as f:\n",
    "    json.dump(valid_metrics, f, indent=2)\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, \"transformer_test_metrics.json\"), \"w\") as f:\n",
    "    json.dump(test_metrics, f, indent=2)\n",
    "\n",
    "# Predict on test\n",
    "pred_out = trainer.predict(test_tok)\n",
    "test_logits = pred_out.predictions\n",
    "test_pred_ids = np.argmax(test_logits, axis=-1)\n",
    "\n",
    "pred_df = test_df.copy()\n",
    "pred_df[\"pred_id\"] = test_pred_ids\n",
    "pred_df[\"pred_label\"] = pred_df[\"pred_id\"].map(ID2LABEL)\n",
    "\n",
    "pred_path = os.path.join(RESULTS_DIR, \"transformer_test_predictions.csv\")\n",
    "pred_df.to_csv(pred_path, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", os.path.join(RESULTS_DIR, \"transformer_valid_metrics.json\"))\n",
    "print(\"-\", os.path.join(RESULTS_DIR, \"transformer_test_metrics.json\"))\n",
    "print(\"-\", pred_path)\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806c865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: ../results/transformer_runs/final_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_OUT = os.path.join(RUN_DIR, \"final_model\")\n",
    "trainer.save_model(MODEL_OUT)\n",
    "tokenizer.save_pretrained(MODEL_OUT)\n",
    "print(\"Saved model to:\", MODEL_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c1fa08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE (valid): acc 0.21495327102803738 macro_f1 0.19583751645282768\n",
      "TRANSFORMER (valid): acc 0.235202492211838 macro_f1 0.13648470159419065\n",
      "TRANSFORMER (test): acc 0.23283346487766376 macro_f1 0.13390705378410298\n",
      "\n",
      "Top confusions:\n",
      "     true_label   pred_label  count\n",
      "0  barely-true    half-true     71\n",
      "1  mostly-true    half-true     71\n",
      "2    half-true        false     69\n",
      "3  barely-true        false     61\n",
      "4        false    half-true     55\n",
      "5    half-true  mostly-true     54\n",
      "6  mostly-true         true     46\n",
      "7        false  mostly-true     44\n",
      "8         true    half-true     43\n",
      "9  mostly-true        false     43\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "\n",
    "with open(\"../results/baseline_metrics.json\") as f:\n",
    "    base = json.load(f)\n",
    "\n",
    "with open(\"../results/transformer_valid_metrics.json\") as f:\n",
    "    tval = json.load(f)\n",
    "\n",
    "with open(\"../results/transformer_test_metrics.json\") as f:\n",
    "    ttest = json.load(f)\n",
    "\n",
    "conf = pd.read_csv(\"../results/top_confusions.csv\")\n",
    "\n",
    "print(\"BASELINE (valid): acc\", base[\"accuracy\"], \"macro_f1\", base[\"macro_f1\"])\n",
    "print(\"TRANSFORMER (valid): acc\", tval.get(\"eval_accuracy\"), \"macro_f1\", tval.get(\"eval_f1_macro\"))\n",
    "print(\"TRANSFORMER (test): acc\", ttest.get(\"eval_accuracy\"), \"macro_f1\", ttest.get(\"eval_f1_macro\"))\n",
    "print(\"\\nTop confusions:\\n\", conf.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
