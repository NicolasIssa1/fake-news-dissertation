{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efca6c0",
   "metadata": {},
   "source": [
    "# 04 — Evaluation & Error Analysis (Baselines)\n",
    "\n",
    "**Dissertation context (what we are doing):**\n",
    "This notebook turns the baseline experiments (TF-IDF + Logistic Regression / Naive Bayes) into *report-ready evidence*:\n",
    "1) Reproducible evaluation (metrics + confusion matrix) on the validation split.\n",
    "2) Error analysis to identify systematic failure modes (what the model confuses and why).\n",
    "3) Clear justification for controlled baseline variants (Week 3) and transformer models (Week 4).\n",
    "\n",
    "This supports the Method 3 research-led structure: experiments → evaluation → interpretation → justified next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b01ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a017ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS_DIR: /workspaces/fake-news-dissertation/results\n",
      "Exists baseline_metrics.json: True\n",
      "Exists confusion_matrix.csv: True\n",
      "Exists valid_predictions.csv: True\n"
     ]
    }
   ],
   "source": [
    "# From notebooks/04_evaluation.ipynb, repo-root results is typically ../results\n",
    "RESULTS_DIR = Path(\"..\") / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metrics_path = RESULTS_DIR / \"baseline_metrics.json\"\n",
    "cm_path = RESULTS_DIR / \"confusion_matrix.csv\"\n",
    "preds_path = RESULTS_DIR / \"valid_predictions.csv\"\n",
    "\n",
    "print(\"RESULTS_DIR:\", RESULTS_DIR.resolve())\n",
    "print(\"Exists baseline_metrics.json:\", metrics_path.exists())\n",
    "print(\"Exists confusion_matrix.csv:\", cm_path.exists())\n",
    "print(\"Exists valid_predictions.csv:\", preds_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4df753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded baseline_metrics.json keys: ['model', 'split', 'tfidf_ngram', 'stop_words', 'max_features', 'class_weight', 'accuracy', 'macro_precision', 'macro_recall', 'macro_f1', 'weighted_precision', 'weighted_recall', 'weighted_f1']\n",
      "Loaded confusion_matrix.csv shape: (6, 7)\n",
      "    Unnamed: 0  true  mostly-true  half-true  barely-true  false  pants-fire\n",
      "0         true    38           42         43           13     32           1\n",
      "1  mostly-true    46           62         71           28     43           1\n",
      "2    half-true    30           54         58           35     69           2\n",
      "3  barely-true    34           37         71           31     61           3\n",
      "4        false    35           44         55           42     81           6\n",
      "Loaded valid_predictions.csv shape: (1284, 3)\n",
      "Columns: ['statement', 'true_label', 'pred_label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>half-true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement   true_label   pred_label\n",
       "0  We have less Americans working now than in the...  barely-true        false\n",
       "1  When Obama was sworn into office, he DID NOT u...   pants-fire         true\n",
       "2  Says Having organizations parading as being so...        false        false\n",
       "3     Says nearly half of Oregons children are poor.    half-true         true\n",
       "4  On attacks by Republicans that various program...    half-true  barely-true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metrics JSON (if it exists)\n",
    "baseline_metrics = None\n",
    "if metrics_path.exists():\n",
    "    with open(metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        baseline_metrics = json.load(f)\n",
    "    print(\"Loaded baseline_metrics.json keys:\", list(baseline_metrics.keys()))\n",
    "else:\n",
    "    print(\"baseline_metrics.json not found — we'll compute metrics from predictions instead.\")\n",
    "\n",
    "# Load confusion matrix CSV (if it exists)\n",
    "cm_df = None\n",
    "if cm_path.exists():\n",
    "    cm_df = pd.read_csv(cm_path)\n",
    "    print(\"Loaded confusion_matrix.csv shape:\", cm_df.shape)\n",
    "    print(cm_df.head())\n",
    "else:\n",
    "    print(\"confusion_matrix.csv not found — we'll compute it from predictions instead.\")\n",
    "\n",
    "# Load predictions CSV (required for reproducibility + error analysis)\n",
    "preds_df = pd.read_csv(preds_path)\n",
    "print(\"Loaded valid_predictions.csv shape:\", preds_df.shape)\n",
    "print(\"Columns:\", list(preds_df.columns))\n",
    "preds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd581fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected true label column: true_label\n",
      "Detected predicted label column: pred_label\n",
      "Unique true labels: ['barely-true', 'false', 'half-true', 'mostly-true', 'pants-fire', 'true'] ...\n",
      "Unique pred labels: ['barely-true', 'false', 'half-true', 'mostly-true', 'pants-fire', 'true'] ...\n"
     ]
    }
   ],
   "source": [
    "def find_first_matching_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "TRUE_CANDIDATES = [\"y_true\", \"true\", \"true_label\", \"label\", \"gold\", \"target\", \"actual\"]\n",
    "PRED_CANDIDATES = [\"y_pred\", \"pred\", \"pred_label\", \"prediction\", \"predicted\", \"output\"]\n",
    "\n",
    "true_col = find_first_matching_col(preds_df, TRUE_CANDIDATES)\n",
    "pred_col = find_first_matching_col(preds_df, PRED_CANDIDATES)\n",
    "\n",
    "print(\"Detected true label column:\", true_col)\n",
    "print(\"Detected predicted label column:\", pred_col)\n",
    "\n",
    "if true_col is None or pred_col is None:\n",
    "    raise ValueError(\n",
    "        \"Could not auto-detect label columns. \"\n",
    "        \"Please rename columns or add your true/pred column names to TRUE_CANDIDATES/PRED_CANDIDATES.\"\n",
    "    )\n",
    "\n",
    "y_true = preds_df[true_col].astype(str)\n",
    "y_pred = preds_df[pred_col].astype(str)\n",
    "\n",
    "print(\"Unique true labels:\", sorted(y_true.unique())[:20], \"...\")\n",
    "print(\"Unique pred labels:\", sorted(y_pred.unique())[:20], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e60af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': np.float64(0.21495327102803738),\n",
       " 'macro_precision': 0.22730155958184264,\n",
       " 'macro_recall': 0.19937426791806,\n",
       " 'macro_f1': 0.19583751645282768,\n",
       " 'weighted_f1': 0.20764931818879773,\n",
       " 'labels_order': ['barely-true',\n",
       "  'false',\n",
       "  'half-true',\n",
       "  'mostly-true',\n",
       "  'pants-fire',\n",
       "  'true']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(set(y_true.unique()) | set(y_pred.unique()))\n",
    "\n",
    "def confusion_matrix_np(y_true, y_pred, labels):\n",
    "    idx = {lab:i for i, lab in enumerate(labels)}\n",
    "    cm = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[idx[t], idx[p]] += 1\n",
    "    return cm\n",
    "\n",
    "cm = confusion_matrix_np(y_true, y_pred, labels)\n",
    "\n",
    "# Accuracy\n",
    "acc = np.trace(cm) / np.sum(cm) if np.sum(cm) else 0.0\n",
    "\n",
    "# Per-class precision/recall/F1\n",
    "tp = np.diag(cm)\n",
    "fp = np.sum(cm, axis=0) - tp\n",
    "fn = np.sum(cm, axis=1) - tp\n",
    "\n",
    "precision = np.divide(tp, tp + fp, out=np.zeros_like(tp, dtype=float), where=(tp+fp)!=0)\n",
    "recall    = np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp+fn)!=0)\n",
    "f1        = np.divide(2*precision*recall, precision+recall, out=np.zeros_like(tp, dtype=float), where=(precision+recall)!=0)\n",
    "\n",
    "macro_p = float(np.mean(precision))\n",
    "macro_r = float(np.mean(recall))\n",
    "macro_f1 = float(np.mean(f1))\n",
    "\n",
    "support = np.sum(cm, axis=1)\n",
    "weighted_f1 = float(np.average(f1, weights=support)) if support.sum() else 0.0\n",
    "\n",
    "computed_metrics = {\n",
    "    \"accuracy\": acc,\n",
    "    \"macro_precision\": macro_p,\n",
    "    \"macro_recall\": macro_r,\n",
    "    \"macro_f1\": macro_f1,\n",
    "    \"weighted_f1\": weighted_f1,\n",
    "    \"labels_order\": labels\n",
    "}\n",
    "computed_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47c1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/baseline_metrics_recomputed.json\n"
     ]
    }
   ],
   "source": [
    "# Save computed metrics (keeps results reproducible and report-ready)\n",
    "out_metrics_path = RESULTS_DIR / \"baseline_metrics_recomputed.json\"\n",
    "with open(out_metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(computed_metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", out_metrics_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069acbd",
   "metadata": {},
   "source": [
    "## Reporting (Chapter 4)\n",
    "\n",
    "**What these metrics mean in dissertation terms:**\n",
    "- We report **macro-F1** because LIAR is multi-class and imbalanced; macro-F1 treats each class equally.\n",
    "- Accuracy alone can hide poor performance on minority labels.\n",
    "- This establishes a reproducible baseline benchmark to compare against controlled variants (Week 3) and transformer models (Week 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb83435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/confusion_matrix_recomputed.csv\n"
     ]
    }
   ],
   "source": [
    "cm_df_recomputed = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "cm_df_recomputed.head()\n",
    "\n",
    "out_cm_path = RESULTS_DIR / \"confusion_matrix_recomputed.csv\"\n",
    "cm_df_recomputed.to_csv(out_cm_path)\n",
    "print(\"Saved:\", out_cm_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db1f571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>false</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false</td>\n",
       "      <td>half-true</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>true</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>false</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>false</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>false</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>true</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           true         pred  count\n",
       "0   barely-true    half-true     71\n",
       "1   mostly-true    half-true     71\n",
       "2     half-true        false     69\n",
       "3   barely-true        false     61\n",
       "4         false    half-true     55\n",
       "5     half-true  mostly-true     54\n",
       "6   mostly-true         true     46\n",
       "7         false  mostly-true     44\n",
       "8          true    half-true     43\n",
       "9   mostly-true        false     43\n",
       "10        false  barely-true     42\n",
       "11         true  mostly-true     42\n",
       "12  barely-true  mostly-true     37\n",
       "13    half-true  barely-true     35\n",
       "14        false         true     35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = preds_df[y_true != y_pred].copy()\n",
    "errors[\"true\"] = y_true[y_true != y_pred].values\n",
    "errors[\"pred\"] = y_pred[y_true != y_pred].values\n",
    "\n",
    "pair_counts = (\n",
    "    errors.groupby([\"true\", \"pred\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "pair_counts.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5880245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected text column: statement\n",
      "\n",
      "=== Confusion: true=barely-true → pred=half-true ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>If people work and make more money, they lose ...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Walker says hes for lower taxes. But Milwaukee...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Says Carlos Lopez-Cantera even voiced enthusia...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>The CBOs latest report confirms what Republica...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Says Mitt Romney once supported President Obam...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Toledo is fourth in the nation behind much big...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>The American people will not support doing any...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Pregnant women who stand for five to six hours...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             statement         true       pred\n",
       "25   If people work and make more money, they lose ...  barely-true  half-true\n",
       "33   Walker says hes for lower taxes. But Milwaukee...  barely-true  half-true\n",
       "64   Says Carlos Lopez-Cantera even voiced enthusia...  barely-true  half-true\n",
       "66   The CBOs latest report confirms what Republica...  barely-true  half-true\n",
       "70   Says Mitt Romney once supported President Obam...  barely-true  half-true\n",
       "85   Toledo is fourth in the nation behind much big...  barely-true  half-true\n",
       "130  The American people will not support doing any...  barely-true  half-true\n",
       "146  Pregnant women who stand for five to six hours...  barely-true  half-true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion: true=mostly-true → pred=half-true ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>We are poised to get rid of over 1,000 more re...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>The military has spent $500 million enforcing ...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>There has been $5 trillion in debt added over ...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Mitt Romney has proposed cutting his own taxes...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>94 percent of winning candidates in 2010 had m...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Congress will begin its recess without having ...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Democrats already agreed to a deal that Republ...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Says legislation pending in the House would ef...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             statement         true       pred\n",
       "26   We are poised to get rid of over 1,000 more re...  mostly-true  half-true\n",
       "48   The military has spent $500 million enforcing ...  mostly-true  half-true\n",
       "55   There has been $5 trillion in debt added over ...  mostly-true  half-true\n",
       "76   Mitt Romney has proposed cutting his own taxes...  mostly-true  half-true\n",
       "86   94 percent of winning candidates in 2010 had m...  mostly-true  half-true\n",
       "93   Congress will begin its recess without having ...  mostly-true  half-true\n",
       "101  Democrats already agreed to a deal that Republ...  mostly-true  half-true\n",
       "129  Says legislation pending in the House would ef...  mostly-true  half-true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try to detect a text column for showing examples (optional but helpful)\n",
    "TEXT_CANDIDATES = [\"text\", \"statement\", \"claim\", \"sentence\", \"content\"]\n",
    "text_col = find_first_matching_col(preds_df, TEXT_CANDIDATES)\n",
    "print(\"Detected text column:\", text_col)\n",
    "\n",
    "top_pairs = pair_counts.head(2)[[\"true\", \"pred\"]].values.tolist()\n",
    "top_pairs\n",
    "\n",
    "def show_confusion_examples(df_errors, true_label, pred_label, n=8, text_col=None):\n",
    "    subset = df_errors[(df_errors[\"true\"] == true_label) & (df_errors[\"pred\"] == pred_label)].copy()\n",
    "    subset = subset.head(n)\n",
    "    cols = []\n",
    "    if text_col and text_col in subset.columns:\n",
    "        cols.append(text_col)\n",
    "    # Include anything useful if present (id/confidence/etc.)\n",
    "    extra = [c for c in [\"id\", \"statement_id\", \"confidence\", \"prob\", \"proba\", \"pred_prob\"] if c in subset.columns]\n",
    "    cols = cols + extra + [\"true\", \"pred\"]\n",
    "    return subset[cols] if cols else subset\n",
    "\n",
    "for t, p in top_pairs:\n",
    "    print(f\"\\n=== Confusion: true={t} → pred={p} ===\")\n",
    "    display(show_confusion_examples(errors, t, p, n=8, text_col=text_col))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bbdc5",
   "metadata": {},
   "source": [
    "### Error analysis notes (write as you inspect)\n",
    "\n",
    "For the confusion **[TRUE] → [PRED]**, the model appears to fail because:\n",
    "- …\n",
    "- …\n",
    "- …\n",
    "\n",
    "Hypothesis (dissertation): TF-IDF relies on surface lexical cues and struggles with:\n",
    "- negation / phrasing nuance (bigrams help),\n",
    "- subtle label boundaries in LIAR (adjacent classes),\n",
    "- missing context/evidence beyond the statement text (transformers may help).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea40b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-Precision</th>\n",
       "      <th>Macro-Recall</th>\n",
       "      <th>Macro-F1</th>\n",
       "      <th>Weighted-F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (from valid_predictions.csv)</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.2076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model       Split  Accuracy  \\\n",
       "0  Baseline (from valid_predictions.csv)  Validation     0.215   \n",
       "\n",
       "   Macro-Precision  Macro-Recall  Macro-F1  Weighted-F1  \n",
       "0           0.2273        0.1994    0.1958       0.2076  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_table = pd.DataFrame([{\n",
    "    \"Model\": \"Baseline (from valid_predictions.csv)\",\n",
    "    \"Split\": \"Validation\",\n",
    "    \"Accuracy\": round(computed_metrics[\"accuracy\"], 4),\n",
    "    \"Macro-Precision\": round(computed_metrics[\"macro_precision\"], 4),\n",
    "    \"Macro-Recall\": round(computed_metrics[\"macro_recall\"], 4),\n",
    "    \"Macro-F1\": round(computed_metrics[\"macro_f1\"], 4),\n",
    "    \"Weighted-F1\": round(computed_metrics[\"weighted_f1\"], 4),\n",
    "}])\n",
    "\n",
    "baseline_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cdf7da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: ../results/valid_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PRED_PATH = os.path.join(RESULTS_DIR, \"valid_predictions.csv\")\n",
    "\n",
    "assert os.path.exists(PRED_PATH), f\"Missing: {PRED_PATH}\"\n",
    "print(\"Found:\", PRED_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37fee499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1284\n",
      "                                           statement   true_label pred_label\n",
      "0  We have less Americans working now than in the...  barely-true      false\n",
      "1  When Obama was sworn into office, he DID NOT u...   pants-fire       true\n",
      "2  Says Having organizations parading as being so...        false      false\n",
      "\n",
      "Label counts (true):\n",
      "true_label\n",
      "false          263\n",
      "mostly-true    251\n",
      "half-true      248\n",
      "barely-true    237\n",
      "true           169\n",
      "pants-fire     116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "preds = pd.read_csv(PRED_PATH)\n",
    "\n",
    "required_cols = {\"statement\", \"true_label\", \"pred_label\"}\n",
    "assert required_cols.issubset(preds.columns), f\"CSV columns are: {preds.columns.tolist()}\"\n",
    "\n",
    "print(\"Rows:\", len(preds))\n",
    "print(preds.head(3))\n",
    "print(\"\\nLabel counts (true):\")\n",
    "print(preds[\"true_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b82270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/confusion_matrix_final.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>half-true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>pants-fire</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barely-true</th>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>42</td>\n",
       "      <td>81</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half-true</th>\n",
       "      <td>35</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostly-true</th>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pants-fire</th>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred         barely-true  false  half-true  mostly-true  pants-fire  true\n",
       "true                                                                     \n",
       "barely-true           31     61         71           37           3    34\n",
       "false                 42     81         55           44           6    35\n",
       "half-true             35     69         58           54           2    30\n",
       "mostly-true           28     43         71           62           1    46\n",
       "pants-fire            30     35         18           11           6    16\n",
       "true                  13     32         43           42           1    38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(preds[\"true_label\"].unique().tolist())\n",
    "cm = pd.crosstab(preds[\"true_label\"], preds[\"pred_label\"], rownames=[\"true\"], colnames=[\"pred\"], dropna=False)\n",
    "\n",
    "# Ensure full square matrix with consistent order\n",
    "cm = cm.reindex(index=labels, columns=labels, fill_value=0)\n",
    "\n",
    "cm_path = os.path.join(RESULTS_DIR, \"confusion_matrix_final.csv\")\n",
    "cm.to_csv(cm_path)\n",
    "\n",
    "print(\"Saved:\", cm_path)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63a8e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspaces/fake-news-dissertation/results/per_class_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pants-fire</th>\n",
       "      <td>pants-fire</td>\n",
       "      <td>116</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barely-true</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>237</td>\n",
       "      <td>0.173184</td>\n",
       "      <td>0.130802</td>\n",
       "      <td>0.149038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half-true</th>\n",
       "      <td>half-true</td>\n",
       "      <td>248</td>\n",
       "      <td>0.183544</td>\n",
       "      <td>0.233871</td>\n",
       "      <td>0.205674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>true</td>\n",
       "      <td>169</td>\n",
       "      <td>0.190955</td>\n",
       "      <td>0.224852</td>\n",
       "      <td>0.206522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostly-true</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>251</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.247012</td>\n",
       "      <td>0.247505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>false</td>\n",
       "      <td>263</td>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.307985</td>\n",
       "      <td>0.277397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label  support  precision    recall        f1\n",
       "pants-fire    pants-fire      116   0.315789  0.051724  0.088889\n",
       "barely-true  barely-true      237   0.173184  0.130802  0.149038\n",
       "half-true      half-true      248   0.183544  0.233871  0.205674\n",
       "true                true      169   0.190955  0.224852  0.206522\n",
       "mostly-true  mostly-true      251   0.248000  0.247012  0.247505\n",
       "false              false      263   0.252336  0.307985  0.277397"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cm is already a numpy array in your notebook\n",
    "cm_np = cm.astype(float)\n",
    "\n",
    "tp = np.diag(cm_np)\n",
    "fp = cm_np.sum(axis=0) - tp\n",
    "fn = cm_np.sum(axis=1) - tp\n",
    "\n",
    "precision = np.divide(tp, tp + fp, out=np.zeros_like(tp), where=(tp+fp)!=0)\n",
    "recall    = np.divide(tp, tp + fn, out=np.zeros_like(tp), where=(tp+fn)!=0)\n",
    "f1        = np.divide(2*precision*recall, precision+recall, out=np.zeros_like(tp), where=(precision+recall)!=0)\n",
    "support   = cm_np.sum(axis=1)\n",
    "\n",
    "per_class = pd.DataFrame({\n",
    "    \"label\": labels,\n",
    "    \"support\": support.astype(int),\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1\n",
    "}).sort_values(\"f1\")\n",
    "\n",
    "per_class_path = RESULTS_DIR / \"per_class_metrics.csv\"\n",
    "per_class.to_csv(per_class_path, index=False)\n",
    "\n",
    "print(\"Saved:\", per_class_path.resolve())\n",
    "per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed7fff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/top_confusions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>false</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false</td>\n",
       "      <td>half-true</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>true</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>false</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>false</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>false</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>true</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_label   pred_label  count\n",
       "0   barely-true    half-true     71\n",
       "1   mostly-true    half-true     71\n",
       "2     half-true        false     69\n",
       "3   barely-true        false     61\n",
       "4         false    half-true     55\n",
       "5     half-true  mostly-true     54\n",
       "6   mostly-true         true     46\n",
       "7         false  mostly-true     44\n",
       "8          true    half-true     43\n",
       "9   mostly-true        false     43\n",
       "10        false  barely-true     42\n",
       "11         true  mostly-true     42\n",
       "12  barely-true  mostly-true     37\n",
       "13    half-true  barely-true     35\n",
       "14        false         true     35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = preds[preds[\"true_label\"] != preds[\"pred_label\"]].copy()\n",
    "\n",
    "conf_pairs = (\n",
    "    errors.groupby([\"true_label\", \"pred_label\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "conf_pairs_path = os.path.join(RESULTS_DIR, \"top_confusions.csv\")\n",
    "conf_pairs.to_csv(conf_pairs_path, index=False)\n",
    "\n",
    "print(\"Saved:\", conf_pairs_path)\n",
    "conf_pairs.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9be505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/error_examples_top3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says Ron Johnson justifies his support of trad...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If people work and make more money, they lose ...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eric Cantor took $5 million from Sheldon Adels...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Says Mitt Romney once supported President Obam...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scott Walker supported the same transportation...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Says there are a half a trillion dollars in cu...</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>barely-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As a result of Roe vs. Wade, Americas maternal...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We are poised to get rid of over 1,000 more re...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm the first person who really took up the is...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94 percent of winning candidates in 2010 had m...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Medicare and Medicaid are the single biggest d...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Says that under the Obama administration, the ...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>half-true</td>\n",
       "      <td>mostly-true -&gt; half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(George) LeMieux never requested a single earm...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>half-true -&gt; false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>John McCains chief economic adviser during the...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>half-true -&gt; false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Says that in 2001, Rick Perry spoke favorably ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>half-true -&gt; false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Marco Rubio \"supported $800,000 for AstroTurf ...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>half-true -&gt; false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Says Gov. Scott Walkers budget includes tax br...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>half-true -&gt; false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Says Congressman Steve Rothman voted against f...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>false</td>\n",
       "      <td>half-true -&gt; false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            statement   true_label pred_label  \\\n",
       "0   Says Ron Johnson justifies his support of trad...  barely-true  half-true   \n",
       "1   If people work and make more money, they lose ...  barely-true  half-true   \n",
       "2   Eric Cantor took $5 million from Sheldon Adels...  barely-true  half-true   \n",
       "3   Says Mitt Romney once supported President Obam...  barely-true  half-true   \n",
       "4   Scott Walker supported the same transportation...  barely-true  half-true   \n",
       "5   Says there are a half a trillion dollars in cu...  barely-true  half-true   \n",
       "6   As a result of Roe vs. Wade, Americas maternal...  mostly-true  half-true   \n",
       "7   We are poised to get rid of over 1,000 more re...  mostly-true  half-true   \n",
       "8   I'm the first person who really took up the is...  mostly-true  half-true   \n",
       "9   94 percent of winning candidates in 2010 had m...  mostly-true  half-true   \n",
       "10  Medicare and Medicaid are the single biggest d...  mostly-true  half-true   \n",
       "11  Says that under the Obama administration, the ...  mostly-true  half-true   \n",
       "12  (George) LeMieux never requested a single earm...    half-true      false   \n",
       "13  John McCains chief economic adviser during the...    half-true      false   \n",
       "14  Says that in 2001, Rick Perry spoke favorably ...    half-true      false   \n",
       "15  Marco Rubio \"supported $800,000 for AstroTurf ...    half-true      false   \n",
       "16  Says Gov. Scott Walkers budget includes tax br...    half-true      false   \n",
       "17  Says Congressman Steve Rothman voted against f...    half-true      false   \n",
       "\n",
       "                        pair  \n",
       "0   barely-true -> half-true  \n",
       "1   barely-true -> half-true  \n",
       "2   barely-true -> half-true  \n",
       "3   barely-true -> half-true  \n",
       "4   barely-true -> half-true  \n",
       "5   barely-true -> half-true  \n",
       "6   mostly-true -> half-true  \n",
       "7   mostly-true -> half-true  \n",
       "8   mostly-true -> half-true  \n",
       "9   mostly-true -> half-true  \n",
       "10  mostly-true -> half-true  \n",
       "11  mostly-true -> half-true  \n",
       "12        half-true -> false  \n",
       "13        half-true -> false  \n",
       "14        half-true -> false  \n",
       "15        half-true -> false  \n",
       "16        half-true -> false  \n",
       "17        half-true -> false  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_confusion(true_label, pred_label, n=5, seed=42):\n",
    "    subset = errors[(errors.true_label == true_label) & (errors.pred_label == pred_label)]\n",
    "    if len(subset) == 0:\n",
    "        return pd.DataFrame(columns=[\"statement\", \"true_label\", \"pred_label\"])\n",
    "    return subset.sample(min(n, len(subset)), random_state=seed)[[\"statement\", \"true_label\", \"pred_label\"]]\n",
    "\n",
    "# Take the top 3 confusion pairs and sample examples\n",
    "top3 = conf_pairs.head(3)\n",
    "samples = []\n",
    "\n",
    "for _, row in top3.iterrows():\n",
    "    t, p = row[\"true_label\"], row[\"pred_label\"]\n",
    "    ex = sample_confusion(t, p, n=6)\n",
    "    ex[\"pair\"] = f\"{t} -> {p}\"\n",
    "    samples.append(ex)\n",
    "\n",
    "examples_df = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "examples_path = os.path.join(RESULTS_DIR, \"error_examples_top3.csv\")\n",
    "examples_df.to_csv(examples_path, index=False)\n",
    "\n",
    "print(\"Saved:\", examples_path)\n",
    "examples_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b191d5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (TF-IDF + Logistic Regression) on the validation set achieved accuracy=0.215 and macro-F1=0.196.\n",
      "Per-class results show uneven performance across the six veracity categories, indicating that the model struggles with fine-grained distinctions.\n",
      "Error analysis using the confusion matrix shows that misclassifications are concentrated between semantically adjacent labels (e.g., nearby truthfulness levels),\n",
      "suggesting that surface-level TF-IDF features do not reliably capture the contextual cues needed for subtle veracity judgement.\n",
      "These findings motivate the use of more context-aware neural language models in subsequent experiments.\n"
     ]
    }
   ],
   "source": [
    "# Load your baseline metrics (use recomputed or original; both match)\n",
    "metrics_path = os.path.join(RESULTS_DIR, \"baseline_metrics.json\")\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, \"r\") as f:\n",
    "        m = json.load(f)\n",
    "else:\n",
    "    with open(os.path.join(RESULTS_DIR, \"baseline_metrics_recomputed.json\"), \"r\") as f:\n",
    "        m = json.load(f)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Baseline (TF-IDF + Logistic Regression) on the validation set achieved accuracy={m['accuracy']:.3f} and macro-F1={m['macro_f1']:.3f}.\n",
    "Per-class results show uneven performance across the six veracity categories, indicating that the model struggles with fine-grained distinctions.\n",
    "Error analysis using the confusion matrix shows that misclassifications are concentrated between semantically adjacent labels (e.g., nearby truthfulness levels),\n",
    "suggesting that surface-level TF-IDF features do not reliably capture the contextual cues needed for subtle veracity judgement.\n",
    "These findings motivate the use of more context-aware neural language models in subsequent experiments.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae66dc",
   "metadata": {},
   "source": [
    "## 4.X Baseline evaluation (validation)\n",
    "\n",
    "The TF-IDF + Logistic Regression baseline achieved **accuracy = 0.215** and **macro-F1 = 0.196** on the validation split. Macro-F1 is reported because the LIAR dataset is multi-class and imbalanced; it weights each class equally and therefore reflects poor performance on minority or difficult labels.\n",
    "\n",
    "## 4.X.1 Per-class performance\n",
    "\n",
    "Per-class results show uneven performance across the six veracity categories. In particular, **pants-fire** exhibits very low recall, indicating that the baseline model rarely identifies extreme falsehood correctly. This suggests that TF-IDF features capture shallow lexical cues but fail to learn reliable patterns for rare or semantically complex classes.\n",
    "\n",
    "## 4.X.2 Error analysis (confusions)\n",
    "\n",
    "The confusion matrix shows that misclassifications are concentrated between semantically adjacent labels (e.g., barely-true ↔ half-true, mostly-true ↔ half-true). This pattern indicates that the bag-of-words assumption struggles to represent contextual nuance needed for fine-grained veracity classification.\n",
    "\n",
    "Qualitative inspection of misclassified statements (Appendix / Error Examples) suggests three baseline failure modes:\n",
    "1) reliance on surface phrasing rather than evidence or context,\n",
    "2) difficulty with subtle wording differences that shift truthfulness level,\n",
    "3) label boundary ambiguity in the dataset (adjacent classes are difficult even for humans).\n",
    "\n",
    "These findings motivate controlled classical variants (e.g., n-grams, class weighting) and subsequently transformer-based models that better capture context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b77e8045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK 1 — N predictions vs sum(confusion matrix)\n",
      "N predictions: 1284\n",
      "Sum confusion matrix: 1284\n",
      "\n",
      "CHECK 2 — Sum(per-class support) vs N predictions\n",
      "Sum support: 1284\n",
      "N predictions: 1284\n",
      "\n",
      "CHECK 3 — Errors in preds vs sum(top_confusions)\n",
      "Errors from preds: 1008\n",
      "Sum top_confusions counts: 1008\n",
      "\n",
      "CHECK 4 — Example pairs match the top-3 confusion pairs\n",
      "Top-3 pairs: {'half-true -> false', 'mostly-true -> half-true', 'barely-true -> half-true'}\n",
      "Example pairs: {'half-true -> false', 'mostly-true -> half-true', 'barely-true -> half-true'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "R = Path(\"..\") / \"results\"\n",
    "\n",
    "preds = pd.read_csv(R / \"valid_predictions.csv\")\n",
    "cm = pd.read_csv(R / \"confusion_matrix_final.csv\", index_col=0)\n",
    "per_class = pd.read_csv(R / \"per_class_metrics.csv\")\n",
    "top = pd.read_csv(R / \"top_confusions.csv\")\n",
    "examples = pd.read_csv(R / \"error_examples_top3.csv\")\n",
    "\n",
    "print(\"CHECK 1 — N predictions vs sum(confusion matrix)\")\n",
    "print(\"N predictions:\", len(preds))\n",
    "print(\"Sum confusion matrix:\", cm.to_numpy().sum())\n",
    "\n",
    "print(\"\\nCHECK 2 — Sum(per-class support) vs N predictions\")\n",
    "print(\"Sum support:\", per_class[\"support\"].sum())\n",
    "print(\"N predictions:\", len(preds))\n",
    "\n",
    "print(\"\\nCHECK 3 — Errors in preds vs sum(top_confusions)\")\n",
    "n_errors = (preds[\"true_label\"] != preds[\"pred_label\"]).sum()\n",
    "print(\"Errors from preds:\", n_errors)\n",
    "print(\"Sum top_confusions counts:\", top[\"count\"].sum())\n",
    "\n",
    "print(\"\\nCHECK 4 — Example pairs match the top-3 confusion pairs\")\n",
    "top3_pairs = set(top.head(3).apply(lambda r: f\"{r['true_label']} -> {r['pred_label']}\", axis=1))\n",
    "example_pairs = set(examples[\"pair\"].unique())\n",
    "print(\"Top-3 pairs:\", top3_pairs)\n",
    "print(\"Example pairs:\", example_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96eb6d",
   "metadata": {},
   "source": [
    "## 4.X Baseline Evaluation (Validation)\n",
    "\n",
    "The TF-IDF + Logistic Regression baseline provides a reproducible point of comparison for subsequent experiments. On the validation split (n=1284), the model achieved accuracy ≈ 0.215 and macro-F1 ≈ 0.196. Macro-F1 is prioritised because LIAR is a six-class problem with class imbalance; it reflects performance across all labels rather than being dominated by majority classes.\n",
    "\n",
    "## 4.X.1 Confusion patterns\n",
    "\n",
    "Error analysis shows that misclassifications concentrate between *adjacent* veracity categories. The three most frequent confusions were:\n",
    "- barely-true → half-true\n",
    "- mostly-true → half-true\n",
    "- half-true → false\n",
    "\n",
    "This indicates the baseline tends to collapse fine-grained distinctions into neighbouring categories, particularly predicting “half-true” as a middle class.\n",
    "\n",
    "## 4.X.2 Interpreting baseline limitations\n",
    "\n",
    "These patterns are consistent with limitations of bag-of-words TF-IDF representations: the model relies on surface lexical cues and struggles to capture contextual nuance required for subtle truthfulness grading. This motivates controlled baseline improvements (e.g., n-grams and class weighting) and, subsequently, transformer-based models that better encode semantic context.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
